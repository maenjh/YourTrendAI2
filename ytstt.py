import streamlit as st
import subprocess
import json
import whisper
import os
import torch  # GPU, MPS í™•ì¸ìš©

# yt-dlpë¥¼ ì´ìš©í•˜ì—¬ ìœ íŠœë¸Œ ê²€ìƒ‰ ê²°ê³¼(ì˜ìƒ URL, ì œëª© ë“±)ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def search_videos(query, max_results=5):
    """
    yt-dlp ëª…ë ¹ì–´:
      --dump-json : ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ì¶œë ¥
      ytsearch{N}: ìœ íŠœë¸Œì—ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ Nê°œ ê°€ì ¸ì˜´
    """
    cmd = f'yt-dlp --dump-json "ytsearch{max_results}:{query}"'
    output = subprocess.check_output(cmd, shell=True).decode("utf-8")
    
    results = []
    for line in output.strip().split("\n"):
        data = json.loads(line)
        video_title = data["title"]
        video_url = data["webpage_url"]
        results.append((video_title, video_url))
    return results


# ì„ íƒëœ ìœ íŠœë¸Œ ì˜ìƒì„ ì˜¤ë””ì˜¤(mp3)ë¡œ ë‹¤ìš´ë¡œë“œ
def download_audio(url, output_name="temp.mp3"):
    """
    yt-dlp ëª…ë ¹ì–´:
      -x : ì˜¤ë””ì˜¤ë§Œ ì¶”ì¶œ
      --audio-format mp3 : ì˜¤ë””ì˜¤ í¬ë§·ì„ mp3ë¡œ ì§€ì •
      -o "temp.%(ext)s" : ì¶œë ¥ íŒŒì¼ ì´ë¦„ íŒ¨í„´ ì§€ì • (temp)
    """
    cmd = f'yt-dlp -x --audio-format mp3 {url} -o "temp.%(ext)s"'
    subprocess.run(cmd, shell=True)

    # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ "temp.mp3"ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if os.path.exists("temp.mp3"):
        return "temp.mp3"
    else:
        return None


# Whisper ëª¨ë¸ì„ ì´ìš©í•´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
def transcribe_audio(model, audio_file):
    result = model.transcribe(audio_file)
    return result["text"]


def detect_device():
    """CUDA, MPS, CPU ì¤‘ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒ"""
    if torch.cuda.is_available():
        return "cuda"
    elif torch.backends.mps.is_available():
        return "mps"
    else:
        return "cpu"


def main():
    st.title("ğŸ™ï¸ YouTube ê²€ìƒ‰ ë° STT ì•±")
    st.write("ìœ íŠœë¸Œ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê³ , ì„ íƒí•œ ì˜ìƒì„ Whisperë¡œ STTí•˜ì—¬ txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

    query = st.text_input("ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", value="")
    
    if "results" not in st.session_state:
        st.session_state["results"] = []
    
    if st.button("ğŸ” ê²€ìƒ‰"):
        if not query.strip():
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ìœ íŠœë¸Œ ê²€ìƒ‰ ì¤‘..."):
                st.session_state["results"] = search_videos(query, max_results=5)
    
    if st.session_state["results"]:
        selected = st.selectbox(
            "ğŸ¬ ì˜ìƒì„ ì„ íƒí•˜ì„¸ìš”",
            st.session_state["results"],
            format_func=lambda x: x[0]
        )
        
        if selected:
            st.write("**ì„ íƒí•œ ì˜ìƒ**:", selected[0])
            
            if st.button("â–¶ï¸ STT ì‹œì‘"):
                with st.spinner("ğŸ§ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                    audio_path = download_audio(selected[1])
                    
                if not audio_path:
                    st.error("ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return
                
                with st.spinner("ğŸ“¦ Whisper ëª¨ë¸ ë¡œë”© ì¤‘..."):
                    device = detect_device()
                    st.info(f"ë””ë°”ì´ìŠ¤: `{device}` ì—ì„œ ëª¨ë¸ ë¡œë“œ ì¤‘...")
                    model = whisper.load_model("base", device=device)
                    
                with st.spinner("ğŸ“ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                    text = transcribe_audio(model, audio_path)
                
                st.success("ğŸ‰ ë³€í™˜ ì™„ë£Œ!")
                st.text_area("ğŸ“„ STT ê²°ê³¼", text, height=300)
                
                if st.button("ğŸ’¾ TXT íŒŒì¼ë¡œ ì €ì¥"):
                    with open("transcription.txt", "w", encoding="utf-8") as f:
                        f.write(text)
                    st.success("âœ… transcription.txt íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")


if __name__ == "__main__":
    main()
