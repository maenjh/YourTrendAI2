import streamlit as st
import whisper
import yt_dlp
#from openai import OpenAI
import os
from dotenv import load_dotenv
from youtubesearchpython import VideosSearch
import pandas as pd
from typing import List, Dict
import ollama
load_dotenv()

def clean_view_count(view_data: dict) -> int:
    """ì¡°íšŒìˆ˜ ë°ì´í„°ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
    try:
        if isinstance(view_data, dict):
            view_text = view_data.get('short', '0')
        else:
            view_text = str(view_data)

        number = ''.join(filter(lambda x: x.isdigit() or x in 'KMB.', view_text.upper()))
        
        if not number:
            return 0

        multiplier = 1
        if 'K' in number:
            multiplier = 1000
            number = number.replace('K', '')
        elif 'M' in number:
            multiplier = 1000000
            number = number.replace('M', '')
        elif 'B' in number:
            multiplier = 1000000000
            number = number.replace('B', '')

        return int(float(number) * multiplier)
    except Exception as e:
        return 0

def truncate_to_complete_sentence(text: str, max_tokens: int) -> str:
    estimated_tokens = len(text.split()) * 1.3
    
    if estimated_tokens <= max_tokens:
        return text
        
    approx_chars = int(max_tokens * 4)
    sentence_endings = ['. ', '! ', '? ', '.\n', '!\n', '?\n']
    truncated_text = text[:approx_chars]
    
    last_sentence_end = -1
    for ending in sentence_endings:
        pos = truncated_text.rfind(ending)
        if pos > last_sentence_end:
            last_sentence_end = pos
            
    if last_sentence_end != -1:
        return text[:last_sentence_end + 2].strip()
    
    last_space = truncated_text.rfind(' ')
    if last_space != -1:
        return text[:last_space].strip() + "..."
        
    return truncated_text.strip() + "..."

class AIAgent:
    def __init__(self, name: str, role: str, temperature: float, personality: str):
        self.name = name
        self.role = role
        self.temperature = temperature
        self.personality = personality
        self.conversation_history: List[Dict] = []
        
    def generate_response(self, topic: str, other_response: str = "", context: str = "", round_num: int = 1) -> str:
        if round_num == 1:
            prompt = f"""
ë‹¹ì‹ ì€ {self.name}ì´ë©°, {self.role}ì…ë‹ˆë‹¤.
ì„±ê²©ê³¼ ë§íˆ¬: {self.personality}

í† ë¡  ì£¼ì œ: {topic}

ë¶„ì„í•  ì½˜í…ì¸ :
{context}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ìƒí™© ë¶„ì„
2. ê¸°íšŒ ìš”ì†Œ ë°œê²¬
3. í•´ê²° ë°©ì•ˆ ì œì‹œ
4. êµ¬ì²´ì  ì‹¤í–‰ ê³„íš
5. ì˜ˆìƒë˜ëŠ” ë„ì „ ê³¼ì œ
"""
        else:
            prompt = f"""
ë‹¹ì‹ ì€ {self.name}ì´ë©°, {self.role}ì…ë‹ˆë‹¤.
ì„±ê²©ê³¼ ë§íˆ¬: {self.personality}

ì´ì „ ëŒ€í™”:
{other_response}

ìœ„ ë‚´ìš©ì— ëŒ€í•œ ì§§ì€ í”¼ë“œë°±ê³¼ ì œì•ˆì„ 200ì ì´ë‚´ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.
"""
    
        try:
            response = ollama.chat(
                model="llama3.2:latest",
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": topic}
                ],
                stream=False,
                options={
                    "temperature": self.temperature,
                    "num_predict": 200 if round_num > 1 else 1000,
                }
            )
            
            generated_response = response.message.content.strip()
            self.conversation_history.append({"role": "assistant", "content": generated_response})
            
            return generated_response

        except Exception as e:
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        
        
def search_videos(keyword: str, duration: str = 'any', sort: str = 'relevance') -> pd.DataFrame:
    try:
        videos_search = VideosSearch(keyword, limit=10)
        search_result = videos_search.result()
        
        if not search_result or 'result' not in search_result:
            return pd.DataFrame()
            
        results = []
        
        for video in search_result['result']:
            try:
                duration_str = video.get('duration', '0:00')
                duration_parts = duration_str.split(':')
                total_minutes = 0
                
                if len(duration_parts) == 2:  # MM:SS
                    total_minutes = int(duration_parts[0])
                elif len(duration_parts) == 3:  # HH:MM:SS
                    total_minutes = int(duration_parts[0]) * 60 + int(duration_parts[1])
                
                if duration == 'short' and total_minutes > 5:
                    continue
                elif duration == 'medium' and (total_minutes <= 5 or total_minutes > 15):
                    continue
                elif duration == 'long' and total_minutes <= 15:
                    continue
                
                view_count = clean_view_count(video.get('viewCount', {}))
                thumbnails = video.get('thumbnails', [])
                thumbnail_url = thumbnails[0].get('url', '') if thumbnails else ''
                
                results.append({
                    'video_id': video.get('id', ''),
                    'title': video.get('title', '').strip(),
                    'url': f"https://www.youtube.com/watch?v={video.get('id', '')}",
                    'thumbnail': thumbnail_url,
                    'duration': duration_str,
                    'view_count': view_count,
                    'author': video.get('channel', {}).get('name', '').strip()
                })
                
            except Exception as e:
                st.warning(f"ë¹„ë””ì˜¤ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
        
        if not results:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
            
        df = pd.DataFrame(results)
        
        if sort == 'date':
            if 'publishedTime' in df.columns:
                df = df.sort_values('publishedTime', ascending=False)
        elif sort == 'views':
            df = df.sort_values('view_count', ascending=False)
            
        return df
        
    except Exception as e:
        st.error(f"ì˜ìƒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()

def format_views(view_count: int) -> str:
    try:
        if not isinstance(view_count, (int, float)):
            return "0"
            
        if view_count >= 1000000000:
            return f"{view_count/1000000000:.1f}B"
        elif view_count >= 1000000:
            return f"{view_count/1000000:.1f}M"
        elif view_count >= 1000:
            return f"{view_count/1000:.1f}K"
        return str(view_count)
    except:
        return "0"

def download_audio(video_url: str) -> str:
    try:
        ydl_opts = {
            'format': 'bestaudio/best',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'outtmpl': 'audio_%(id)s.%(ext)s'
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(video_url, download=True)
            audio_path = f"audio_{info['id']}.mp3"
            return audio_path
            
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# def transcribe_audio(audio_path: str) -> str:
#     try:
#         # CUDA GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
#         import torch
#         device = "cuda" if torch.cuda.is_available() else "cpu"
        
#         if device == "cpu":
#             st.warning("âš ï¸ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•„ CPUì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤. ìŒì„± ì¸ì‹ ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
#         else:
#             st.info("ğŸš€ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ ì¸ì‹í•©ë‹ˆë‹¤.")
        
#         # Whisper ëª¨ë¸ ë¡œë“œ ì‹œ device ì§€ì •
#         model = whisper.load_model("medium", device=device)
        
#         # GPU ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ ì„¤ì •
#         if device == "cuda":
#             model.to(device)
        
#         # transcribe ì‹œ device ì§€ì •
#         result = model.transcribe(
#             audio_path,
#             fp16=False if device == "cpu" else True  # GPUì¼ ë•Œë§Œ FP16 ì‚¬ìš©
#         )
        
#         return result["text"]
        
#     except Exception as e:
#         st.error(f"ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
#         return None

def transcribe_audio(audio_path: str) -> str:
    try:
        import platform
        import torch

        # ìš´ì˜ ì²´ì œ í™•ì¸
        system = platform.system()

        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if system == "Darwin" and torch.backends.mps.is_available():
            device = "mps"
            st.info("ğŸš€ macOSì—ì„œ M2 ì¹© GPU(MPS)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ ì¸ì‹í•©ë‹ˆë‹¤.")
        elif system == "Windows" and torch.cuda.is_available():
            device = "cuda"
            st.info("ğŸš€ Windowsì—ì„œ CUDA GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ ì¸ì‹í•©ë‹ˆë‹¤.")
        else:
            device = "cpu"
            if system == "Darwin":
                st.warning("âš ï¸ macOSì—ì„œ GPU(MPS)ê°€ ê°ì§€ë˜ì§€ ì•Šì•„ CPUì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            elif system == "Windows":
                st.warning("âš ï¸ Windowsì—ì„œ CUDA GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•„ CPUì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            else:
                st.info("ğŸ’» ì§€ì›ë˜ì§€ ì•ŠëŠ” ìš´ì˜ ì²´ì œì—ì„œ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # Whisper ëª¨ë¸ ë¡œë“œ
        model = whisper.load_model("medium", device=device)

        # transcribe ì‹¤í–‰
        result = model.transcribe(
            audio_path,
            fp16=False if device in ["cpu", "mps"] else True  # FP16 ì„¤ì •
        )

        return result["text"]
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""
def create_context(transcripts: List[str], video_urls: List[str]) -> str:
    return "".join([
        f"\n[ì˜ìƒ {i+1}] URL: {url}\nì˜ìƒ ë‚´ìš© ìš”ì•½:\n{transcript}\n{'-'*50}"
        for i, (transcript, url) in enumerate(zip(transcripts, video_urls))
    ])

def display_message(agent_name: str, message: str):
    style = {
        "ì‹œì¥ë¶„ì„ê°€": {
            "bg_color": "#E8F4F9",
            "border_color": "#2196F3",
            "icon": "ğŸ“Š"
        },
        "í”„ë¡œë•íŠ¸ ë§¤ë‹ˆì €": {
            "bg_color": "#F3E5F5",
            "border_color": "#9C27B0",
            "icon": "ğŸ’¡"
        },
        "í…Œí¬ë¦¬ë“œ": {
            "bg_color": "#E8F5E9",
            "border_color": "#4CAF50",
            "icon": "âš™ï¸"
        },
        "ì‚¬ì—…ì „ëµê°€": {
            "bg_color": "#FFF3E0",
            "border_color": "#FF9800",
            "icon": "ğŸ“ˆ"
        }
    }
    
    agent_style = style.get(agent_name, {
        "bg_color": "#F5F5F5",
        "border_color": "#9E9E9E",
        "icon": "ğŸ’­"
    })
    
    st.markdown(f"""
        <div style="
            background-color: {agent_style['bg_color']};
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
            border-left: 4px solid {agent_style['border_color']};
        ">
            <strong>{agent_style['icon']} {agent_name}</strong><br>{message}
        </div>
    """, unsafe_allow_html=True)

def generate_discussion(transcripts: List[str], video_urls: List[str], user_prompt: str) -> tuple:
    analyst = AIAgent(
        name="ì‹œì¥ë¶„ì„ê°€",
        role="ì‹œì¥ íŠ¸ë Œë“œì™€ ì‚¬ìš©ì ë‹ˆì¦ˆ ë¶„ì„ ì „ë¬¸ê°€",
        temperature=0.7,
        personality="ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ë©°, ì‹œì¥ì˜ ê¸°íšŒì™€ ìœ„í—˜ ìš”ì†Œë¥¼ íŒŒì•…í•©ë‹ˆë‹¤."
    )
    
    product_manager = AIAgent(
        name="í”„ë¡œë•íŠ¸ ë§¤ë‹ˆì €",
        role="ì œí’ˆ ê¸°íš ë° ì „ëµ ìˆ˜ë¦½ ì „ë¬¸ê°€",
        temperature=0.8,
        personality="ì‚¬ìš©ì ì¤‘ì‹¬ì  ì‚¬ê³ ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ë¥¼ ê· í˜•ìˆê²Œ ê³ ë ¤í•©ë‹ˆë‹¤."
    )
    
    tech_lead = AIAgent(
        name="í…Œí¬ë¦¬ë“œ",
        role="ê¸°ìˆ  êµ¬í˜„ ë° ì•„í‚¤í…ì²˜ ì„¤ê³„ ì „ë¬¸ê°€",
        temperature=0.7,
        personality="ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ì´í•´í•˜ê³  ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤."
    )
    
    business_strategist = AIAgent(
        name="ì‚¬ì—…ì „ëµê°€",
        role="ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë° ìˆ˜ìµí™” ì „ëµ ì „ë¬¸ê°€",
        temperature=0.8,
        personality="ì‹œì¥ì„±ê³¼ ìˆ˜ìµì„±ì„ ê³ ë ¤í•œ ì‚¬ì—… ì „ëµì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤."
    )

    context = create_context(transcripts, video_urls)
    conversation = []
    agents = [analyst, product_manager, tech_lead, business_strategist]
    rounds = 3
    
    for round_num in range(rounds):
        st.markdown(f"### ğŸ”„ ë¼ìš´ë“œ {round_num + 1}")
        
        for agent in agents:
            with st.spinner(f'{agent.name}ì˜ ì˜ê²¬ì„ ë¶„ì„ ì¤‘...'):
                other_responses = "\n\n".join([
                    f"{msg['agent']}: {msg['response']}"
                    for msg in conversation[-4:] if msg['agent'] != agent.name
                ])
                
                response = agent.generate_response(
                    user_prompt, 
                    other_responses, 
                    context,
                    round_num + 1
                )
                
                conversation.append({
                    "agent": agent.name,
                    "response": response,
                    "round": round_num + 1
                })
                
                display_message(agent.name, response)
        
        st.markdown(f"""
        <div style="padding: 10px; margin: 20px 0; text-align: center; background-color: #f0f2f6; border-radius: 10px;">
            âœ¨ ë¼ìš´ë“œ {round_num + 1} ì™„ë£Œ
        </div>
        """, unsafe_allow_html=True)
    
    final_summary = generate_final_summary(conversation, user_prompt)
    return final_summary, conversation

def generate_final_summary(conversation: List[dict], user_prompt: str) -> str:
    conversation_summary = "\n\n".join([
        f"ë¼ìš´ë“œ {msg['round']} - {msg['agent']}: {msg['response'][:300]}"
        for msg in conversation
    ])
    
    prompt = f"""
ì£¼ì œ: {user_prompt}

ì „ë¬¸ê°€ë“¤ì˜ ë…¼ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í•µì‹¬ì ì¸ ì œì•ˆ ì‚¬í•­ë§Œ ê°„ë‹¨íˆ ì •ë¦¬í•´ì£¼ì„¸ìš”:

1. í”„ë¡œì íŠ¸ ê°œìš”
2. í•µì‹¬ ê¸°ëŠ¥
3. ê¸°ìˆ  êµ¬í˜„ ë°©ì•ˆ
4. ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ
5. ì‹¤í–‰ ê³„íš
6. ì£¼ìš” ê³ ë ¤ì‚¬í•­

ì „ë¬¸ê°€ ë…¼ì˜ ë‚´ìš©:
{conversation_summary}
"""

    try:
        response = ollama.chat(
            model="llama3.2:latest",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": user_prompt}
            ],
            stream=False,
            options={
                "temperature": 0.7,
                "num_predict": 1500,
            }
        )
        
        return response.message.content.strip()
        
    except Exception as e:
        return f"ìµœì¢… ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def generate_idea_from_videos(selected_videos: List[str], user_prompt: str):
    try:
        transcripts = []
        progress_bar = st.progress(0)
        
        # ì˜ìƒ ì²˜ë¦¬ ìµœì í™”
        with st.spinner('ì˜ìƒì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            for i, video_url in enumerate(selected_videos):
                audio_path = download_audio(video_url)
                if audio_path:
                    transcript = transcribe_audio(audio_path)
                    if transcript:
                        # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ ì œí•œ
                        transcripts.append(truncate_to_complete_sentence(transcript, 1000))
                    try:
                        os.remove(audio_path)
                    except:
                        pass
                progress_bar.progress((i + 1) / len(selected_videos))

        if not transcripts:
            st.error("âŒ ì„ íƒëœ ì˜ìƒì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None

        # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ í‘œì‹œ ìµœì í™”
        st.markdown("### ğŸ“ ì¶”ì¶œëœ ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸")
        with st.expander("ìŠ¤í¬ë¦½íŠ¸ ì „ì²´ ë³´ê¸°", expanded=False):
            for i, (transcript, url) in enumerate(zip(transcripts, selected_videos), 1):
                st.markdown(f"""
                <div style="background-color: #f8f9fa; padding: 1rem; border-radius: 10px; margin: 0.5rem 0; border: 1px solid #dee2e6;">
                    <strong>ì˜ìƒ {i}</strong>: {url}
                    <hr style="margin: 0.5rem 0;">
                    <div style="white-space: pre-wrap;">{transcript[:500]}...</div>
                </div>
                """, unsafe_allow_html=True)

        # ì„ íƒëœ ëª¨ë¸ë¡œ í† ë¡  ì§„í–‰
        model = st.session_state.get('selected_model', 'llama-2')
        st.markdown(f"### ğŸ¤– AI ì „ë¬¸ê°€ í† ë¡  ì‹œì‘ (ëª¨ë¸: {model})")
        
        final_summary, conversation = generate_discussion(
            transcripts, 
            selected_videos, 
            user_prompt
        )
            
        return final_summary, conversation
        
    except Exception as e:
        st.error(f"ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, None

def render_enhanced_sidebar():
    with st.sidebar:
        st.header("ğŸ› ï¸ í”„ë¡œì íŠ¸ ì„¤ì •")
        
        # ì§„í–‰ ìƒíƒœ í‘œì‹œ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        st.header("ğŸ“Š ì§„í–‰ ìƒíƒœ")
        current_step = 1
        if 'selected_videos' in st.session_state and st.session_state.selected_videos:
            current_step = 2
        if 'final_summary' in st.session_state and st.session_state.final_summary:
            current_step = 3
            
        progress_bar = st.progress(current_step / 3)
        st.markdown(f"""
        1. ì˜ìƒ ì„ íƒ {'âœ…' if current_step >= 1 else ''}
        2. ì „ë¬¸ê°€ í† ë¡  {'âœ…' if current_step >= 2 else ''}
        3. ìµœì¢… ì œì•ˆì„œ {'âœ…' if current_step >= 3 else ''}
        """)
        
        st.markdown("---")
        
        # AI ì„¤ì •
        st.header("ğŸ¤– AI ì„¤ì •")
        temperature = st.slider(
            "AI ì°½ì˜ì„± ìˆ˜ì¤€",
            min_value=0.0,
            max_value=1.0,
            value=0.7,
            step=0.1,
            help="ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì¸ ê²°ê³¼ê°€ ìƒì„±ë©ë‹ˆë‹¤."
        )
        
        max_tokens = st.select_slider(
            "ì‘ë‹µ ê¸¸ì´",
            options=[1000, 1500, 2000, 2500],
            value=2000,
            format_func=lambda x: f"{x} í† í°",
            help="ìƒì„±ë  ì‘ë‹µì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
        )
        
        st.markdown("---")
        
        # í”„ë¡œì íŠ¸ ì •ë³´
        if 'selected_videos' in st.session_state and st.session_state.selected_videos:
            st.header("ğŸ“Š í”„ë¡œì íŠ¸ í†µê³„")
            st.write(f"ì„ íƒëœ ì˜ìƒ: {len(st.session_state.selected_videos)}ê°œ")
            
            if 'conversation_history' in st.session_state:
                total_rounds = len(set(msg['round'] for msg in st.session_state.conversation_history))
                st.write(f"ì§„í–‰ëœ í† ë¡  ë¼ìš´ë“œ: {total_rounds}íšŒ")
        
        st.markdown("---")
        
        # ë¹ ë¥¸ ì•¡ì…˜
        st.header("âš¡ ë¹ ë¥¸ ì•¡ì…˜")
        if st.button("í”„ë¡œì íŠ¸ ì´ˆê¸°í™”", use_container_width=True):
            for key in ['selected_videos', 'final_summary', 'conversation_history', 
                      'search_results', 'search_performed']:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()
        
        if 'final_summary' in st.session_state:
            if st.button("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (PDF)", use_container_width=True):
                # PDF ë‹¤ìš´ë¡œë“œ ë¡œì§ êµ¬í˜„ í•„ìš”
                st.info("PDF ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì€ ê³§ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.")
        
        # ë„ì›€ë§ ì„¹ì…˜
        st.markdown("---")
        with st.expander("â“ ë„ì›€ë§"):
            st.markdown("""
            **ì‚¬ìš© ë°©ë²•**
            1. ì°¸ê³ í•  ìœ íŠœë¸Œ ì˜ìƒì„ ê²€ìƒ‰í•˜ê³  ì„ íƒí•˜ì„¸ìš”
            2. í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ìƒì„¸íˆ ì‘ì„±í•˜ì„¸ìš”
            3. AI ì „ë¬¸ê°€ í† ë¡ ì„ ì‹œì‘í•˜ì„¸ìš”
            
            **íŒ**
            - 3ê°œ ì´ìƒì˜ ì˜ìƒì„ ì„ íƒí•˜ë©´ ë” ë‹¤ì–‘í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            - AI ì°½ì˜ì„± ìˆ˜ì¤€ì„ ì¡°ì ˆí•˜ì—¬ ë‹¤ì–‘í•œ ê²°ê³¼ë¥¼ ì–»ì–´ë³´ì„¸ìš”
            """)

def main():
    st.set_page_config(
        page_title="ìœ íŠœë¸Œ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ìƒì„±ê¸°",
        page_icon="ğŸ¥",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    if 'selected_videos' not in st.session_state:
        st.session_state.selected_videos = []
    if 'search_performed' not in st.session_state:
        st.session_state.search_performed = False
    if 'discussion_rounds' not in st.session_state:
        st.session_state.discussion_rounds = 2
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = 'llama-2'
        
    # í–¥ìƒëœ ì‚¬ì´ë“œë°” ë Œë”ë§
    render_enhanced_sidebar()
    
    # ê¸°ì¡´ì˜ ë©”ì¸ ì»¨í…Œì´ë„ˆ ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
    # ... (ë‚˜ë¨¸ì§€ ì½”ë“œ)

    # CSS ìŠ¤íƒ€ì¼ ì •ì˜
    st.markdown("""
        <style>
        .main {
            padding: 2rem;
        }
        .stButton>button {
            background-color: #FF0000;
            color: white;
            border-radius: 20px;
            padding: 0.25rem 0.75rem;
            border: none;
            min-height: 0px;
            height: auto;
            line-height: 1.5;
            font-size: 0.85rem;
            width: auto !important;
            display: inline-block;
        }
        .stButton>button:hover {
            background-color: #CC0000;
        }
        .video-card {
            background-color: #f8f9fa;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
            border: 1px solid #dee2e6;
        }
        .expert-opinion {
            background-color: #ffffff;
            padding: 1.5rem;
            border-radius: 10px;
            margin: 1rem 0;
            border-left: 4px solid #1a73e8;
        }
        .discussion-round {
            background-color: #f0f2f6;
            padding: 1rem;
            border-radius: 10px;
            margin: 1.5rem 0;
        }
        .final-summary {
            background-color: #e8f0fe;
            padding: 2rem;
            border-radius: 10px;
            margin: 2rem 0;
            border: 1px solid #4285f4;
        }
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸ¥ ìœ íŠœë¸Œ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ìƒì„±ê¸°")
    st.markdown("##### AI ì „ë¬¸ê°€ë“¤ì˜ í† ë¡ ì„ í†µí•´ í˜ì‹ ì ì¸ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ë°œêµ´í•˜ì„¸ìš”")

    # ì‚¬ì´ë“œë°” êµ¬ì„±
    with st.sidebar:
        st.header("í”„ë¡œì íŠ¸ ì§„í–‰ ë‹¨ê³„")
        current_step = 1
        if 'selected_videos' in st.session_state and st.session_state.selected_videos:
            current_step = 2
        if 'final_summary' in st.session_state and st.session_state.final_summary:
            current_step = 3
            
        progress_bar = st.progress(current_step / 3)
        st.markdown(f"""
        1. ì˜ìƒ ì„ íƒ {'âœ…' if current_step >= 1 else ''}
        2. ì „ë¬¸ê°€ í† ë¡  {'âœ…' if current_step >= 2 else ''}
        3. ìµœì¢… ì œì•ˆì„œ {'âœ…' if current_step >= 3 else ''}
        """)

    # ë©”ì¸ ì»¨í…Œì´ë„ˆ
    with st.container():
        st.header("ğŸ” ì°¸ê³ í•  ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰")
        with st.form(key='search_form'):
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                search_keyword = st.text_input(
                    "ê²€ìƒ‰ì–´ ì…ë ¥",
                    placeholder="ë¶„ì„í•˜ê³  ì‹¶ì€ ì£¼ì œë‚˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                )
            with col2:
                duration_option = st.selectbox(
                    "ì˜ìƒ ê¸¸ì´",
                    options=['any', 'short', 'medium', 'long'],
                    format_func=lambda x: {
                        'any': 'ì „ì²´',
                        'short': '5ë¶„ ì´í•˜',
                        'medium': '5-15ë¶„',
                        'long': '15ë¶„ ì´ìƒ'
                    }[x]
                )
            with col3:
                sort_option = st.selectbox(
                    "ì •ë ¬ ê¸°ì¤€",
                    options=['relevance', 'date', 'views'],
                    format_func=lambda x: {
                        'relevance': 'ê´€ë ¨ë„ìˆœ',
                        'date': 'ìµœì‹ ìˆœ',
                        'views': 'ì¡°íšŒìˆ˜ìˆœ'
                    }[x]
                )
            
            search_submitted = st.form_submit_button("ê²€ìƒ‰", use_container_width=True)

        if search_submitted and search_keyword:
            with st.spinner('ğŸ” ì˜ìƒì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                videos_df = search_videos(search_keyword, duration_option, sort_option)
                if not videos_df.empty:
                    st.session_state.search_results = videos_df
                    st.session_state.search_performed = True

        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        if hasattr(st.session_state, 'search_results') and st.session_state.search_results is not None:
            for _, video in st.session_state.search_results.iterrows():
                cols = st.columns([4, 1])
                with cols[0]:
                    st.markdown(f"""
                    <div class="video-card">
                        <div style="display: flex; align-items: start;">
                            <img src="{video['thumbnail']}" style="width: 200px; border-radius: 10px;"/>
                            <div style="margin-left: 20px; flex-grow: 1;">
                                <h3>{video['title']}</h3>
                                <p>ğŸ‘¤ {video['author']}</p>
                                <p>â±ï¸ {video['duration']} | ğŸ‘ï¸ {format_views(video['view_count'])}</p>
                            </div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                
                with cols[1]:
                    if video['url'] not in st.session_state.selected_videos:
                        if st.button('ì„ íƒ', key=f"select_{video['video_id']}"):
                            st.session_state.selected_videos.append(video['url'])
                            st.success("âœ… ì˜ìƒì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.rerun()
                    else:
                        st.warning("âš ï¸ ì„ íƒë¨")

        # ì„ íƒëœ ì˜ìƒ ëª©ë¡
        if st.session_state.selected_videos:
            st.markdown("---")
            st.header("ğŸ“Œ ì„ íƒëœ ì˜ìƒ ëª©ë¡")
            
            for idx, url in enumerate(st.session_state.selected_videos):
                cols = st.columns([5, 1])
                with cols[0]:
                    st.markdown(f"""
                    <div class="video-card">
                        {idx + 1}. {url}
                    </div>
                    """, unsafe_allow_html=True)
                with cols[1]:
                    if st.button('ì œê±°', key=f'remove_{idx}'):
                        st.session_state.selected_videos.pop(idx)
                        st.rerun()

            # í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì…ë ¥
            st.markdown("---")
            st.header("ğŸ’¡ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì„¤ì •")
            
            user_prompt = st.text_area(
                "í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ì„¤ëª…",
                placeholder="ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ëª©í‘œì™€ ì£¼ìš” ìš”êµ¬ì‚¬í•­ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                height=150,
                key="project_requirements"
            )

            if st.button('AI ì „ë¬¸ê°€ í† ë¡  ì‹œì‘í•˜ê¸°', use_container_width=True):
                if not user_prompt.strip():
                    st.warning("âš ï¸ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner('ì „ë¬¸ê°€ í† ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤...'):
                        final_summary, conversation_history = generate_idea_from_videos(
                            st.session_state.selected_videos,
                            user_prompt
                        )
                        
                        if final_summary and conversation_history:
                            st.session_state.final_summary = final_summary
                            st.session_state.conversation_history = conversation_history

        # ìµœì¢… ê²°ê³¼ í‘œì‹œ
        if 'final_summary' in st.session_state and st.session_state.final_summary:
            st.markdown("---")
            st.header("âœ¨ ìµœì¢… í”„ë¡œì íŠ¸ ì œì•ˆì„œ")
            st.markdown(f"""
            <div class="final-summary">
                {st.session_state.final_summary}
            </div>
            """, unsafe_allow_html=True)
            
            if st.button('ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘í•˜ê¸°', key='new_project', use_container_width=True):
                for key in ['selected_videos', 'final_summary', 'conversation_history', 
                          'search_results', 'search_performed']:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()

if __name__ == "__main__":
    main()